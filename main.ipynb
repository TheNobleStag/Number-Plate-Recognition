{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# model = YOLO(\"yolov8n.pt\")  \n",
    "\n",
    "# model.train(\n",
    "#     data=\"Dataset/data.yaml\",  \n",
    "#     epochs=50,           \n",
    "#     imgsz=640,            \n",
    "#     batch=16,             \n",
    "#     device=\"cuda\"   \n",
    "# )\n",
    "\n",
    "# model_path = \"runs/detect/train/weights/best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection + OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 license-plate, 26.2ms\n",
      "Speed: 5.9ms preprocess, 26.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 20.7ms\n",
      "Speed: 5.5ms preprocess, 20.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 20.8ms\n",
      "Speed: 4.4ms preprocess, 20.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 20.5ms\n",
      "Speed: 3.4ms preprocess, 20.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 20.0ms\n",
      "Speed: 5.1ms preprocess, 20.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 18.4ms\n",
      "Speed: 4.5ms preprocess, 18.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 20.6ms\n",
      "Speed: 2.0ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 18.7ms\n",
      "Speed: 6.2ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 18.8ms\n",
      "Speed: 6.4ms preprocess, 18.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 18.2ms\n",
      "Speed: 4.7ms preprocess, 18.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 license-plates, 17.7ms\n",
      "Speed: 7.1ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 17.3ms\n",
      "Speed: 4.6ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 17.4ms\n",
      "Speed: 4.6ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 17.8ms\n",
      "Speed: 4.0ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 15.8ms\n",
      "Speed: 6.0ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 19.8ms\n",
      "Speed: 6.0ms preprocess, 19.8ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 18.7ms\n",
      "Speed: 2.9ms preprocess, 18.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 16.7ms\n",
      "Speed: 6.4ms preprocess, 16.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 license-plates, 11.3ms\n",
      "Speed: 5.6ms preprocess, 11.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 8.9ms\n",
      "Speed: 9.9ms preprocess, 8.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 17.4ms\n",
      "Speed: 5.4ms preprocess, 17.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 license-plates, 19.7ms\n",
      "Speed: 0.0ms preprocess, 19.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 16.3ms\n",
      "Speed: 7.4ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 16.5ms\n",
      "Speed: 3.8ms preprocess, 16.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 license-plate, 7.3ms\n",
      "Speed: 15.8ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "License plate(s) successfully detected and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train5/weights/best.pt\")\n",
    "\n",
    "input_dir = \"D:/Freelancing/Number Plate/OCR Dataset/test/\"\n",
    "output_dir = \"D:/Freelancing/Number Plate/OCR Dataset/test_cropped/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "image_paths = glob.glob(os.path.join(input_dir, \"*.jpg\"))\n",
    "\n",
    "for image_path in image_paths:\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = model(image)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        for j, box in enumerate(result.boxes.xyxy):\n",
    "            x_min, y_min, x_max, y_max = map(int, box[:4].tolist())\n",
    "\n",
    "            padding = 10  # Adjust the padding value as needed\n",
    "            x_min_padded = max(0, x_min - padding)\n",
    "            y_min_padded = max(0, y_min - padding)\n",
    "            x_max_padded = min(image.shape[1], x_max + padding)\n",
    "            y_max_padded = min(image.shape[0], y_max + padding)\n",
    "            cropped_plate = image[y_min_padded:y_max_padded, x_min_padded:x_max_padded]\n",
    "\n",
    "            output_path = os.path.join(output_dir, f\"cropped_plate_{os.path.basename(image_path).split('.')[0]}_{i}_{j}.jpg\")\n",
    "            cv2.imwrite(output_path, cropped_plate)\n",
    "\n",
    "print(\"License plate(s) successfully detected and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.segmentation import clear_border\n",
    "import imutils\n",
    "import os\n",
    "\n",
    "# Load character templates from a directory\n",
    "def load_templates(template_dir):\n",
    "    templates = {}\n",
    "    for filename in os.listdir(template_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            char_label = os.path.splitext(filename)[0]\n",
    "            template_path = os.path.join(template_dir, filename)\n",
    "            template_image = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "            templates[char_label] = template_image\n",
    "    return templates\n",
    "\n",
    "# Detect license plate using YOLO\n",
    "def detect_license_plate(image, model):\n",
    "    results = model(image)\n",
    "    for result in results:\n",
    "        for box in result.boxes.xyxy:\n",
    "            x_min, y_min, x_max, y_max = map(int, box[:4].tolist())  # Ensure correct indexing\n",
    "            cropped_plate = image[y_min:y_max, x_min:x_max]\n",
    "            return cropped_plate\n",
    "    return None\n",
    "\n",
    "# Convert image to grayscale\n",
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "# Segment characters from a license plate image\n",
    "def segment_characters(plate_image):\n",
    "    gray = preprocess_image(plate_image)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 45, 15)\n",
    "    _, labels = cv2.connectedComponents(thresh)\n",
    "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    total_pixels = plate_image.shape[0] * plate_image.shape[1]\n",
    "    lower = total_pixels // 70\n",
    "    upper = total_pixels // 20\n",
    "\n",
    "    for label in np.unique(labels):\n",
    "        if label == 0:\n",
    "            continue\n",
    "        label_mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        label_mask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(label_mask)\n",
    "        if lower < numPixels < upper:\n",
    "            mask = cv2.add(mask, label_mask)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    bounding_boxes = sorted(bounding_boxes, key=lambda b: (b[1], b[0]))\n",
    "\n",
    "    char_images = [mask[y:y+h, x:x+w] for (x, y, w, h) in bounding_boxes]\n",
    "    return char_images\n",
    "\n",
    "# Template matching using NCC & Phase Correlation\n",
    "def match_template(char_image, templates):\n",
    "    best_match_ncc, best_score_ncc = None, -1\n",
    "    best_match_phase, best_score_phase = None, -1\n",
    "    resized_char = cv2.resize(char_image, (50, 50))\n",
    "\n",
    "    for label, template in templates.items():\n",
    "        template_resized = cv2.resize(template, (50, 50))\n",
    "\n",
    "        # Normalized Cross-Correlation (NCC)\n",
    "        result = cv2.matchTemplate(resized_char, template_resized, cv2.TM_CCOEFF_NORMED)\n",
    "        score_ncc = result.max()\n",
    "        if score_ncc > best_score_ncc:\n",
    "            best_score_ncc = score_ncc\n",
    "            best_match_ncc = label\n",
    "\n",
    "        # Phase Correlation\n",
    "        shift, response = cv2.phaseCorrelate(np.float32(resized_char), np.float32(template_resized))\n",
    "        if response > best_score_phase:\n",
    "            best_score_phase = response\n",
    "            best_match_phase = label\n",
    "\n",
    "    # print(f\"Best match (NCC): {best_match_ncc} ({best_score_ncc})\")\n",
    "    # print(f\"Best match (Phase Correlation): {best_match_phase} ({best_score_phase})\")\n",
    "    return best_match_ncc, best_score_ncc, best_match_phase, best_score_phase\n",
    "\n",
    "# Recognize characters from segmented images\n",
    "def recognize_characters(segmented_chars, templates):\n",
    "    recognized_text_ncc = \"\"\n",
    "    recognized_text_phase = \"\"\n",
    "\n",
    "    for char_img in segmented_chars:\n",
    "        match_ncc, score_ncc, match_phase, score_phase = match_template(char_img, templates)\n",
    "        if match_ncc:\n",
    "            recognized_text_ncc += match_ncc\n",
    "        if match_phase:\n",
    "            recognized_text_phase += match_phase\n",
    "\n",
    "    return recognized_text_ncc, recognized_text_phase\n",
    "\n",
    "# Main function to run the full pipeline\n",
    "def main(image_path, model_path, template_dir):\n",
    "    model = YOLO(model_path)\n",
    "    templates = load_templates(template_dir)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = model(image)\n",
    "    plate_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes.xyxy:\n",
    "            x_min, y_min, x_max, y_max = map(int, box[:4].tolist())  # Ensure correct indexing\n",
    "            cropped_plate = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            plate_filename = f\"cropped_plate_{plate_count}.jpg\"\n",
    "            cv2.imwrite(plate_filename, cropped_plate)\n",
    "            plate_count += 1\n",
    "\n",
    "            segmented_chars = segment_characters(cropped_plate)\n",
    "            print(f\"Segmented {len(segmented_chars)} characters\")\n",
    "            for i, char_img in enumerate(segmented_chars):\n",
    "                char_filename = f\"segmented_char_{plate_count}_{i}.jpg\"\n",
    "                cv2.imwrite(char_filename, char_img)\n",
    "\n",
    "            recognized_text_ncc, recognized_text_phase = recognize_characters(segmented_chars, templates)\n",
    "\n",
    "            print(f\"Recognized License Plate (NCC): {recognized_text_ncc}\")\n",
    "            print(f\"Recognized License Plate (Phase Correlation): {recognized_text_phase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 license-plate, 44.2ms\n",
      "Speed: 4.2ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Segmented 2 characters\n",
      "Recognized License Plate (NCC): X12\n",
      "Recognized License Plate (Phase Correlation): W1X1\n"
     ]
    }
   ],
   "source": [
    "image_path = \"D:/Freelancing/Number Plate/Dataset/Original/18.jpg\"  \n",
    "model_path = \"runs/detect/train4/weights/best.pt\"  \n",
    "template_dir = \"D:/Freelancing/Number Plate/Templates/CharacterImages\"  \n",
    "main(image_path, model_path, template_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Configure tesseract executable path (update this path if necessary)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def recognize_text(image_path):\n",
    "    \"\"\"Use Tesseract OCR to recognize text from the image.\"\"\"\n",
    "    try:\n",
    "        # Open the image file\n",
    "        with Image.open(image_path) as img:\n",
    "            # Use Tesseract to do OCR on the image\n",
    "            text = pytesseract.image_to_string(img)\n",
    "            print(f\"Recognized text: {text}\")\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_directory = 'Dataset/Cropped/'\n",
    "# for filename in os.listdir(image_directory):\n",
    "#     if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "#         print(f\"\\nProcessing {filename}:\")\n",
    "#         recognize_text(os.path.join(image_directory, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** EP Error ***************\n",
      "EP Error D:\\a\\_work\\1\\s\\onnxruntime\\python\\onnxruntime_pybind_state.cc:507 onnxruntime::python::RegisterTensorRTPluginsAsCustomOps Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
      " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "['A0551TT']\n"
     ]
    }
   ],
   "source": [
    "from fast_plate_ocr import ONNXPlateRecognizer\n",
    "\n",
    "m = ONNXPlateRecognizer('argentinian-plates-cnn-model')\n",
    "print(m.run('Dataset\\Cropped\\cropped_plate_112_0_0.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
